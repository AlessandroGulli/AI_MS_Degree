{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVRrTxfboJ61",
        "colab_type": "text"
      },
      "source": [
        "# **Install OpenCV Libraries** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1NJ1-Ddam74",
        "colab_type": "code",
        "outputId": "ab80d891-e836-40c4-b744-fe3078468b24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "!pip uninstall opencv-python -y\n",
        "# downgrade OpenCV a bit since some none-free features are not available\n",
        "#!pip install opencv-contrib-python==3.4.2.17 --force-reinstall\n",
        "%cd /content/drive/My Drive/Unimore/VCS/Project/OpenCV\n",
        "!pip install opencv_contrib_python_headless-4.1.0.25-cp36-cp36m-linux_x86_64.whl --force-reinstall"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling opencv-python-4.1.2.30:\n",
            "  Successfully uninstalled opencv-python-4.1.2.30\n",
            "/content/drive/My Drive/Unimore/VCS/Project/OpenCV\n",
            "Processing ./opencv_contrib_python_headless-4.1.0.25-cp36-cp36m-linux_x86_64.whl\n",
            "Collecting numpy>=1.11.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 5.4MB/s \n",
            "\u001b[31mERROR: imgaug 0.2.9 requires opencv-python, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: dopamine-rl 1.0.5 requires opencv-python>=3.4.1.15, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 requires opencv-python, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, opencv-contrib-python-headless\n",
            "  Found existing installation: numpy 1.18.4\n",
            "    Uninstalling numpy-1.18.4:\n",
            "      Successfully uninstalled numpy-1.18.4\n",
            "Successfully installed numpy-1.18.4 opencv-contrib-python-headless-4.1.0.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ErHHXSqzOA",
        "colab_type": "text"
      },
      "source": [
        "# **Root Path Definition** #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUvl8aX3qoUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = \"/content/drive/My Drive/Unimore/VCS/Project/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxauV5A-vycf",
        "colab_type": "text"
      },
      "source": [
        "# **Convert .MOV to .MP4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmk7PyLlvxe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "638557e2-fc40-4963-8cec-27e6d2b7c166"
      },
      "source": [
        "import subprocess\n",
        "import os\n",
        "import re\n",
        "import subprocess as sp\n",
        "import logging\n",
        "\n",
        "the_file = root_path + \"Videos/IMG_4081.MOV\"\n",
        "out_file = root_path + \"Videos/IMG_4081.MP4\"\n",
        "\n",
        "ffmpeg = sp.Popen(['/usr/bin/ffmpeg', '-i', the_file, out_file], stdout = sp.PIPE, stderr = sp.STDOUT)\n",
        "process_output =  ffmpeg.communicate()\n",
        "print (\"communicate: \" + str(process_output)) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "communicate: (b'ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\\n  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\\n  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\\n  libavutil      55. 78.100 / 55. 78.100\\n  libavcodec     57.107.100 / 57.107.100\\n  libavformat    57. 83.100 / 57. 83.100\\n  libavdevice    57. 10.100 / 57. 10.100\\n  libavfilter     6.107.100 /  6.107.100\\n  libavresample   3.  7.  0 /  3.  7.  0\\n  libswscale      4.  8.100 /  4.  8.100\\n  libswresample   2.  9.100 /  2.  9.100\\n  libpostproc    54.  7.100 / 54.  7.100\\n/content/drive/My Drive/Unimore/VCS/Project/Videos/IMG_4081.MOV: No such file or directory\\n', None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh1cBlIOj8IT",
        "colab_type": "text"
      },
      "source": [
        "# **Import Mask-RCNN Paths**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGAl-Wqxj5FS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "labelsPath = root_path + \"mask-rcnn-coco/object_detection_classes_coco.txt\" \n",
        "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
        "\n",
        "\n",
        "colorsPath = root_path + \"mask-rcnn-coco/colors.txt\" \n",
        "COLORS = open(colorsPath).read().strip().split(\"\\n\")\n",
        "COLORS = [np.array(c.split(\",\")).astype(\"int\") for c in COLORS]\n",
        "COLORS = np.array(COLORS, dtype=\"uint8\")\n",
        "\n",
        "weightsPath = root_path + \"mask-rcnn-coco/frozen_inference_graph.pb\" \n",
        "configPath  = root_path + \"mask-rcnn-coco/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfujhWSt_Uxj",
        "colab_type": "text"
      },
      "source": [
        "# **Retrieve paintings names**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ivkx7FG_Tvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "db = pd.read_csv(root_path + 'data.csv', sep = ',')\n",
        "df = pd.DataFrame(db.values, columns = ['Title','Author','Room','Image']); \n",
        "\n",
        "Title = df.iloc[:,0].values\n",
        "Author = df.iloc[:,1].values\n",
        "Room = df.iloc[:,2].values\n",
        "Image = df.iloc[:,3].values\n",
        "\n",
        "DB_title = df.set_index('Image')['Title'].to_dict()\n",
        "DB_room  = df.set_index('Image')['Room'].to_dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36zyPWjXu13-",
        "colab_type": "text"
      },
      "source": [
        "# **Create features DB file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0VNkQz3uTJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle as pickle\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def extract_sift_features(image_path, sift, nfeatures, vector_size=128):\n",
        "\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "    if type(image) is np.ndarray:\n",
        "        try:            \n",
        "            kp, des = sift.detectAndCompute(image, None)\n",
        "            # Making descriptor of same size\n",
        "            needed_size = (vector_size * nfeatures)\n",
        "            if des.size < needed_size:\n",
        "                # if we have less the nfeatures descriptors then just adding zeros at the\n",
        "                # end of our feature vector\n",
        "                pad = (nfeatures - des.shape[0])                \n",
        "                des = np.pad(des, ((0,pad),(0,0)), 'constant', constant_values=(0))                      \n",
        "        except cv2.error as e:\n",
        "            print ('Error: ' + srt(e))\n",
        "            return None\n",
        "        return des\n",
        "    else:\n",
        "      return None  \n",
        "\n",
        "\n",
        "def batch_extractor(images_path, pickled_db_path, sift):\n",
        "\n",
        "    files = [os.path.join(images_path, p) for p in sorted(os.listdir(images_path))]\n",
        "\n",
        "    result = {}\n",
        "    for f in files:\n",
        "        head, tail = os.path.split(f)\n",
        "        #print ('Extracting features from image ' + str(tail))        \n",
        "        result[tail] = extract_sift_features(f, sift, nfeatures)\n",
        "    \n",
        "    # saving all our feature vectors in pickled file\n",
        "    with open(pickled_db_path, 'wb') as fp:\n",
        "        pickle.dump(result, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJbk-pcxvTz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_path = root_path + 'paintings_db/'\n",
        "pickled_db_path = root_path + 'paintings_db/features.pck'\n",
        "\n",
        "nfeatures = 500\n",
        "sift =  cv2.xfeatures2d.SIFT_create(nfeatures) \n",
        "\n",
        "#batch_extractor(images_path,pickled_db_path, sift) #uncomment this line to extract sift\n",
        "\n",
        "with open(pickled_db_path, 'rb') as fp:\n",
        "  data = pickle.load(fp)\n",
        "  names = []\n",
        "  matrix = []\n",
        "  for k, v in data.items():\n",
        "      names.append(k)\n",
        "      matrix.append(v)\n",
        "  matrix_db = np.array(matrix)\n",
        "  names_db = np.array(names) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMJ8oX0HeR5G",
        "colab_type": "text"
      },
      "source": [
        "# **HOG - SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmvSX9qEtXY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to return HOG features and visualization\n",
        "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
        "    from skimage.feature import hog\n",
        "    if vis == True:\n",
        "        # Use skimage.hog() to get both features and a visualization\n",
        "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell), cells_per_block=(cell_per_block, cell_per_block), visualize=vis, feature_vector=feature_vec)\n",
        "        return features, hog_image\n",
        "    else:      \n",
        "        # Use skimage.hog() to get features only\n",
        "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell), cells_per_block=(cell_per_block, cell_per_block), visualize=vis, feature_vector=feature_vec)\n",
        "        return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8OK3a_Wtiiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_HOG_features(imgs, cspace='RGB', orient=9, pix_per_cell=8, cell_per_block=2, hog_channel=0, dim_img = 64, aug_feat = 6):\n",
        "    \n",
        "    import imageio\n",
        "    import imgaug as ia\n",
        "    import imgaug.augmenters as iaa\n",
        "    \n",
        "    # Create a list to append feature vectors to\n",
        "    features = []\n",
        "    # Iterate through the list of images\n",
        "    for file in os.listdir(imgs):\n",
        "\n",
        "        if str(file) != '.ipynb_checkpoints':\n",
        "            # Read in each one by one\n",
        "            image = cv2.imread(imgs + \"/\" + file)\n",
        "            for i in range(aug_feat):\n",
        "              if i == 0:\n",
        "                image = image\n",
        "              elif i == 1:\n",
        "                rotate=iaa.Affine(rotate=(-30, 30))\n",
        "                image=rotate.augment_image(image)    \n",
        "              elif i == 2:\n",
        "                gaussian_noise=iaa.AdditiveGaussianNoise(10,20)\n",
        "                image=gaussian_noise.augment_image(image)\n",
        "              elif i == 3:\n",
        "                flip_hr=iaa.Fliplr(p=0.7)\n",
        "                image= flip_hr.augment_image(image) \n",
        "              elif i == 4: \n",
        "                shear = iaa.Affine(shear=(0,10))\n",
        "                image=shear.augment_image(image)\n",
        "              elif i == 5:  \n",
        "                crop = iaa.Crop(percent=(0, 0.3)) # crop image\n",
        "                image=crop.augment_image(image)\n",
        "              image = cv2.resize(image, (dim_img,dim_img), interpolation = cv2.INTER_AREA)       \n",
        "              # apply color conversion if other than 'RGB'\n",
        "              if cspace != 'RGB' and cspace != 'GRAY':\n",
        "                  if cspace == 'HSV':\n",
        "                      feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "                  elif cspace == 'LUV':\n",
        "                      feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
        "                  elif cspace == 'HLS':\n",
        "                      feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
        "                  elif cspace == 'Lab':\n",
        "                      feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
        "                  elif cspace == 'YUV':\n",
        "                      feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
        "                  elif cspace == 'YCrCb':\n",
        "                      feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
        "              else:\n",
        "                if cspace == 'GRAY':\n",
        "                  feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "                else:  \n",
        "                  feature_image = np.copy(image)      \n",
        "\n",
        "              # Call get_hog_features() with vis=False, feature_vec=True\n",
        "              if hog_channel == 'ALL':\n",
        "                  hog_features = []\n",
        "                  if cspace != 'GRAY':\n",
        "                    for channel in range(feature_image.shape[2]):\n",
        "                        hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
        "                                            orient, pix_per_cell, cell_per_block, \n",
        "                                            vis=False, feature_vec=True))                    \n",
        "                  else:\n",
        "                        hog_features.append(get_hog_features(feature_image, \n",
        "                                            orient, pix_per_cell, cell_per_block, \n",
        "                                            vis=False, feature_vec=True))   \n",
        "                  hog_features = np.ravel(hog_features)        \n",
        "              else:\n",
        "                if cspace != 'GRAY':\n",
        "                  hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
        "                              pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
        "                else:\n",
        "                  hog_features = get_hog_features(feature_image, orient, \n",
        "                              pix_per_cell, cell_per_block, vis=False, feature_vec=True)  \n",
        "              # Append the new feature vector to the features list\n",
        "              features.append(hog_features)\n",
        "    # Return list of feature vectors\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sJ1JEbctouj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_painting_classifier(path):\n",
        "  # Extraction Parameters\n",
        "  import time\n",
        "  from sklearn.model_selection import train_test_split  \n",
        "  from sklearn.svm import LinearSVC, SVC\n",
        "  from sklearn.calibration import CalibratedClassifierCV  \n",
        "\n",
        "  colorspace = 'Lab' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb, GRAY\n",
        "  orient = 9\n",
        "  pix_per_cell = 8\n",
        "  cell_per_block = 2\n",
        "  hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
        "  dim_img = 128\n",
        "  aug_feat = 3\n",
        "\n",
        "  t = time.time()\n",
        "\n",
        "  painting_features = extract_HOG_features(path + '/Painting', cspace=colorspace, orient=orient,pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel, dim_img = dim_img, aug_feat = aug_feat)\n",
        "  not_painting_features = extract_HOG_features(path + '/Not Painting', cspace=colorspace, orient=orient, pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel, dim_img = dim_img, aug_feat = aug_feat)\n",
        "\n",
        "  t2 = time.time()\n",
        "  print(round(t2-t, 2), 'Seconds to extract HOG features...')\n",
        "\n",
        "\n",
        "  # Create an array stack of feature vectors\n",
        "  X = np.vstack((painting_features, not_painting_features)).astype(np.float64)  \n",
        "\n",
        "  # Define the labels vector\n",
        "  y = np.hstack((np.ones(len(painting_features)), np.zeros(len(not_painting_features))))\n",
        "\n",
        "\n",
        "  # Split up data into randomized training and test sets\n",
        "  rand_state = np.random.randint(0, 100)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
        "\n",
        "  print('Using:',orient,'orientations',pix_per_cell,\n",
        "      'pixels per cell and', cell_per_block,'cells per block')\n",
        "  print('Feature vector length:', len(X_train[0]))\n",
        "\n",
        "  # Use a linear SVC \n",
        "  model = CalibratedClassifierCV(base_estimator=LinearSVC(penalty='l2', dual=False), cv=5)\n",
        "  # Check the training time for the SVC\n",
        "  t = time.time()\n",
        "  model.fit(X_train, y_train)\n",
        "  t2 = time.time()\n",
        "  print(round(t2-t, 2), 'Seconds to train SVC...')\n",
        "  # Check the score of the SVC\n",
        "  print('Test Accuracy of SVC = ', round(model.score(X_test, y_test), 4))\n",
        "  # Check the prediction time for a single sample\n",
        "  t=time.time()\n",
        "  n_predict = 10\n",
        "  print('My SVC predicts:     ', model.predict_proba(X_test[0:n_predict]))\n",
        "  print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
        "  t2 = time.time()\n",
        "  print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4ikNI0atwc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#paint_model = create_painting_classifier(root_path + 'Dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb2WgCJ84EIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving paint_model objects:\n",
        "#with open(root_path + 'Dataset/SVC Model/paint_model.pkl', 'wb') as f:  \n",
        "    #pickle.dump(paint_model, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yVzLYY75YZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting back paint_model:\n",
        "with open(root_path + 'Dataset/SVC Model/paint_model.pkl', 'rb') as f: \n",
        "    paint_model = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0XESya2HRJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_people_statue_classifier(path):\n",
        "\n",
        "  # Extraction Parameters\n",
        "  import time\n",
        "  from sklearn.model_selection import train_test_split  \n",
        "  from sklearn.svm import LinearSVC\n",
        "  from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "  colorspace = 'HLS' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
        "  orient = 44\n",
        "  pix_per_cell = 8\n",
        "  cell_per_block = 1\n",
        "  hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
        "  dim_img = 100\n",
        "  aug_feat = 1\n",
        "\n",
        "  t = time.time()\n",
        "\n",
        "  people_features = extract_HOG_features(path + '/People', cspace=colorspace, orient=orient,pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel, dim_img = dim_img, aug_feat = aug_feat)\n",
        "  statues_features = extract_HOG_features(path + '/Statues', cspace=colorspace, orient=orient, pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel, dim_img = dim_img, aug_feat = aug_feat)\n",
        "\n",
        "  t2 = time.time()\n",
        "  print(round(t2-t, 2), 'Seconds to extract HOG features...')\n",
        "\n",
        "\n",
        "  # Create an array stack of feature vectors\n",
        "  X = np.vstack((people_features, statues_features)).astype(np.float64)  \n",
        "\n",
        "  # Define the labels vector\n",
        "  y = np.hstack((np.ones(len(people_features)), np.zeros(len(statues_features))))\n",
        " \n",
        "\n",
        "  # Split up data into randomized training and test sets\n",
        "  rand_state = np.random.randint(0, 100)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
        "\n",
        "  print('Using:',orient,'orientations',pix_per_cell,\n",
        "      'pixels per cell and', cell_per_block,'cells per block')\n",
        "  print('Feature vector length:', len(X_train[0]))\n",
        "\n",
        "\n",
        "  # Use a linear SVC \n",
        "  people_statue_model = CalibratedClassifierCV(base_estimator=LinearSVC(penalty='l2', dual=False), cv=5)\n",
        "  # Check the training time for the SVC\n",
        "  t = time.time()\n",
        "  people_statue_model.fit(X_train, y_train)\n",
        "  t2 = time.time()\n",
        "  print(round(t2-t, 2), 'Seconds to train SVC...')\n",
        "  # Check the score of the SVC\n",
        "  print('Test Accuracy of SVC = ', round(people_statue_model.score(X_test, y_test), 4))\n",
        "  # Check the prediction time for a single sample\n",
        "  t=time.time()\n",
        "  n_predict = 10\n",
        "  print('My SVC predicts:     ', people_statue_model.predict_proba(X_test[0:n_predict]))\n",
        "  print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
        "  t2 = time.time()\n",
        "  print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n",
        "\n",
        "\n",
        "  return people_statue_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS35rDxlLm8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#people_statue_model = create_people_statue_classifier(root_path + 'Dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TokyFKf60k9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving people_statue_model objects:\n",
        "#with open(root_path + 'Dataset/SVC Model/people_statue_model.pkl', 'wb') as f:  \n",
        "    #pickle.dump(people_statue_model, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lDImvwf69rA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting back paint_model:\n",
        "with open(root_path + 'Dataset/SVC Model/people_statue_model.pkl', 'rb') as f: \n",
        "    people_statue_model = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwcUepWPoW0C",
        "colab_type": "text"
      },
      "source": [
        "# **Delete Images from folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q01JjlpSofei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "folder = '/content/drive/My Drive/Unimore/VCS/Project/Videos/Images' \n",
        "\n",
        "for filename in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, filename)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gduLrDTDo5od",
        "colab_type": "text"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zVxP-njo4tI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "from scipy.spatial import distance as dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VjxeL_Zc9VJ",
        "colab_type": "text"
      },
      "source": [
        "# **Geometric Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY1dYgNt8bgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retrieve_points_coordinates(pts, x_offset= 0, y_offset = 0):\n",
        "\n",
        "  rect = np.zeros((4, 2), dtype=\"int32\")\n",
        "  #tl\n",
        "  rect[0] = (pts[0],pts[1])\n",
        "  rect[0,[0]] += x_offset\n",
        "  rect[0,[1]] += y_offset\n",
        "  #tr\n",
        "  rect[1] = (pts[0]+pts[2],pts[1])\n",
        "  rect[1,[0]] += x_offset\n",
        "  rect[1,[1]] += y_offset\n",
        "  #bl\n",
        "  rect[2] = (pts[0]+pts[2],pts[1]+pts[3])\n",
        "  rect[2,[0]] += x_offset\n",
        "  rect[2,[1]] += y_offset\n",
        "  #br\n",
        "  rect[3] = (pts[0],pts[1]+pts[3])\n",
        "  rect[3,[0]] += x_offset\n",
        "  rect[3,[1]] += y_offset\n",
        "  \n",
        "  return rect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlwcN-tsp-iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def order_points(pts, x_offset= 0, y_offset = 0):\n",
        "  \n",
        "    rect = np.zeros((4, 2), dtype=\"int32\")\n",
        "\n",
        "    s = pts.sum(axis=1)\n",
        "    rect[0] = pts[np.argmin(s)]     \n",
        "    rect[0,[0]] += x_offset\n",
        "    rect[0,[1]] += y_offset\n",
        "    rect[2] = pts[np.argmax(s)]     \n",
        "    rect[2,[0]] += x_offset\n",
        "    rect[2,[1]] += y_offset\n",
        "\n",
        "    diff = np.diff(pts, axis=1)\n",
        "    rect[1] = pts[np.argmin(diff)]\n",
        "    rect[1,[0]] += x_offset\n",
        "    rect[1,[1]] += y_offset\n",
        "    rect[3] = pts[np.argmax(diff)]\n",
        "    rect[3,[0]] += x_offset\n",
        "    rect[3,[1]] += y_offset\n",
        "    # return the ordered coordinates\n",
        "    return rect "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQE6wgFt0Um6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def order_points_warp(pts, x_offset= 0, y_offset = 0):\n",
        "\n",
        "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
        "\n",
        "    s = pts.sum(axis=1)\n",
        "    rect[0] = pts[np.argmin(s)] \n",
        "    rect[0,[0]] += x_offset\n",
        "    rect[0,[1]] += y_offset\n",
        "    rect[2] = pts[np.argmax(s)]  \n",
        "    rect[2,[0]] += x_offset\n",
        "    rect[2,[1]] += y_offset\n",
        "\n",
        "    diff = np.diff(pts, axis=1)\n",
        "    rect[1] = pts[np.argmin(diff)]\n",
        "    rect[1,[0]] += x_offset\n",
        "    rect[1,[1]] += y_offset\n",
        "    rect[3] = pts[np.argmax(diff)]\n",
        "    rect[3,[0]] += x_offset\n",
        "    rect[3,[1]] += y_offset\n",
        "    # return the ordered coordinates\n",
        "    return rect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFFqTvlrc_PJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def order_points_by_clusters(pts, median, x_offset= 0, y_offset = 0):\n",
        "  \n",
        "  rect = np.zeros((4, 2), dtype=\"int32\")\n",
        "\n",
        "  west_cluster = []\n",
        "  east_cluster = []\n",
        "  \n",
        "  for pt in pts:\n",
        "    if pt[0] < int(median - x_offset):\n",
        "      west_cluster.append(pt)\n",
        "    else:\n",
        "      east_cluster.append(pt)  \n",
        "\n",
        "  west_cluster = np.array(west_cluster)\n",
        "  west_cluster = west_cluster.reshape(-2,2)\n",
        "  east_cluster = np.array(east_cluster)\n",
        "  east_cluster = east_cluster.reshape(-2,2)\n",
        "\n",
        "\n",
        "  #print(pts)\n",
        "  #print(median)\n",
        "  #print(west_cluster)\n",
        "  #print(east_cluster)\n",
        "\n",
        "  #print(west_cluster,east_cluster)\n",
        "  [tl_west,tr_west,br_west,bl_west] = order_points(west_cluster)  \n",
        "  [tl_east,tr_east,br_east,bl_east] = order_points(east_cluster)\n",
        "\n",
        "  rect[0] = tl_west\n",
        "  rect[0,[0]] += x_offset\n",
        "  rect[0,[1]] += y_offset\n",
        "  rect[1] = tr_east\n",
        "  rect[1,[0]] += x_offset\n",
        "  rect[1,[1]] += y_offset \n",
        "  rect[2] = br_east\n",
        "  rect[2,[0]] += x_offset\n",
        "  rect[2,[1]] += y_offset \n",
        "  rect[3] = bl_west\n",
        "  rect[3,[0]] += x_offset\n",
        "  rect[3,[1]] += y_offset \n",
        "\n",
        "  return rect\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0Z6YTVdUonE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sum_offset_coordinates(coordinates, x_offset= 0, y_offset = 0):\n",
        "  \n",
        "  for i in range(len(coordinates)):\n",
        "    coordinates[i,[0]] += x_offset\n",
        "    coordinates[i,[1]] += y_offset\n",
        "\n",
        "  return coordinates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lyJTWLQdXEM",
        "colab_type": "text"
      },
      "source": [
        "# **Perspective Transform**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65-YBCgLp1og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perspective_transform(image, pts):\n",
        "\n",
        "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
        "\n",
        "    rect = order_points_warp(pts)\n",
        "    (tl, tr, br, bl) = pts\n",
        "\n",
        "    width_A = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
        "    width_B = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
        "    max_width = max(int(width_A), int(width_B))\n",
        "\n",
        "    height_A = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
        "    height_B = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
        "    max_height = max(int(height_A), int(height_B))\n",
        "\n",
        "    dst = np.array([\n",
        "      [0, 0],\n",
        "      [max_width - 1, 0],\n",
        "      [max_width - 1, max_height - 1],\n",
        "      [0, max_height - 1]], dtype = \"float32\")\n",
        "    \n",
        "    M = cv2.getPerspectiveTransform(rect, dst)\n",
        "    warped = cv2.warpPerspective(image, M, (max_width, max_height))\n",
        "    \n",
        "    return warped"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFB_hH39dbhs",
        "colab_type": "text"
      },
      "source": [
        "# **Binary Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXF-SYJ8q1sE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_image(img): \n",
        "\n",
        "  gray_img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)           \n",
        "  element = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
        "  closing = cv2.morphologyEx(gray_img, cv2.MORPH_GRADIENT, element)\n",
        "  morph_simple_img = cv2.morphologyEx(closing, cv2.MORPH_CLOSE, element)\n",
        "  morph_simple_img = cv2.cvtColor(morph_simple_img,cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "  #DEBUG\n",
        "  #plt.figure(figsize = (20,10))\n",
        "  #plt.imshow(morph_simple_img, cmap=plt.cm.gray, interpolation='nearest')\n",
        "\n",
        "  black_detect = img.copy()\n",
        "  mask = cv2.compare(black_detect,65,cv2.CMP_LT)\n",
        "  black_detect[mask > 0] = 255\n",
        "  black_detect = cv2.cvtColor(black_detect,cv2.COLOR_RGB2GRAY)\n",
        "  black_detect = cv2.GaussianBlur(black_detect,(5,5),0)\n",
        "  _, black_detect = cv2.threshold(black_detect, 240, 255, cv2.THRESH_BINARY)  \n",
        "  black_detect = black_detect*(255/np.max(black_detect))\n",
        "  binary_black_detect = np.zeros_like(black_detect)  \n",
        "  binary_black_detect[black_detect > 0] = 1\n",
        "\n",
        "\n",
        "  Lab_img = cv2.cvtColor(morph_simple_img, cv2.COLOR_RGB2Lab)\n",
        "\n",
        "  L = Lab_img[:,:,0]  \n",
        "\n",
        "  thresh_L = (0, 10)\n",
        "  L = L*(255/np.max(L))\n",
        "  binary_L = np.zeros_like(L)\n",
        "  binary_L[(L > thresh_L[0]) & (L <= thresh_L[1])] = 1\n",
        "\n",
        "  #DEBUG\n",
        "  #plt.figure(figsize = (20,10))\n",
        "  #plt.imshow(binary_L, cmap=plt.cm.gray, interpolation='nearest')\n",
        "    \n",
        "  cont_merge = np.zeros_like(L) \n",
        "  cont_merge[(binary_L == 0) | (binary_black_detect == 1)] = 1\n",
        "\n",
        "  #DEBUG\n",
        "  #plt.figure(figsize = (20,10))\n",
        "  #plt.imshow(cont_merge, cmap=plt.cm.gray, interpolation='nearest')\n",
        "\n",
        "  contours_merge, hierarchy_merge = cv2.findContours(np.uint8(cont_merge), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  # Draw contours\n",
        "  drawing_merge = np.zeros((binary_L.shape[0], binary_L.shape[1], 3), dtype=np.uint8)\n",
        "  contours_merge = sorted(contours_merge, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "  for index, el in enumerate(contours_merge):\n",
        "    if cv2.contourArea(el) > 20000:\n",
        "        cv2.drawContours(drawing_merge, contours_merge, index, 255, thickness=-1) \n",
        "      \n",
        "  binary_merge_Filtered = cv2.cvtColor(drawing_merge, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  #DEBUG\n",
        "  #plt.figure(figsize = (20,10))\n",
        "  #plt.imshow(binary_merge_Filtered, cmap=plt.cm.gray, interpolation='nearest')\n",
        "\n",
        "  return binary_merge_Filtered"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwT9Bbv1qX4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_outliers(x,y,w,h,orizontal_dim,vertical_dim):\n",
        "\n",
        "  ret = False\n",
        "  general_threshold = 3.5\n",
        "  border_threshold  = 2.5\n",
        "\n",
        "  if w > h:\n",
        "    ratio = w/h\n",
        "  else:\n",
        "    ratio = h/w\n",
        "\n",
        "  #print(ratio)\n",
        "\n",
        "  if ratio >= general_threshold:\n",
        "    ret = True  \n",
        "\n",
        "  if ret == False:\n",
        "    if (w*h) < (0.005*(orizontal_dim*vertical_dim)):\n",
        "        ret = True\n",
        "\n",
        "  return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0DHdFqndqvg",
        "colab_type": "text"
      },
      "source": [
        "# **SVM Classifications**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZLXDngVVidT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def people_classification(warped_image, people_statue_model):\n",
        "        \n",
        "    valid_match = 0\n",
        "\n",
        "    orient = 44\n",
        "    pix_per_cell = 8\n",
        "    cell_per_block = 1\n",
        "    \n",
        "    warped_image = cv2.resize(warped_image, (100,100), interpolation = cv2.INTER_AREA) \n",
        "    warped_image = cv2.cvtColor(warped_image, cv2.COLOR_RGB2HLS)\n",
        "    test_hog_features = []\n",
        "    for channel in range(warped_image.shape[2]):\n",
        "        test_hog_features.append(get_hog_features(warped_image[:,:,channel], orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True))\n",
        "    test_hog_features = np.ravel(test_hog_features)\n",
        "\n",
        "    \n",
        "    #print(people_statue_model.predict_proba(test_hog_features.reshape(1,-1))[0][1])\n",
        "    if people_statue_model.predict_proba(test_hog_features.reshape(1,-1))[0][1] > 0.57:\n",
        "        valid_match = 1\n",
        "    else:\n",
        "        valid_match = 0\n",
        "\n",
        "    return  valid_match  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeLmMFc1fngZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def painting_classification(image, model):\n",
        "\n",
        "    valid_match = 0\n",
        "\n",
        "    orient = 9\n",
        "    pix_per_cell = 8\n",
        "    cell_per_block = 2\n",
        "    \n",
        "    image = cv2.resize(image, (128,128), interpolation = cv2.INTER_AREA)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
        "\n",
        "    test_hog_features = []\n",
        "    for channel in range(image.shape[2]):\n",
        "        test_hog_features.append(get_hog_features(image[:,:,channel], orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True))\n",
        "    test_hog_features = np.ravel(test_hog_features)\n",
        "\n",
        "    valid_match = model.predict_proba(test_hog_features.reshape(1,-1))[0][1]\n",
        "    #print(valid_match)\n",
        "\n",
        "    return valid_match"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qBcTFoddy0r",
        "colab_type": "text"
      },
      "source": [
        "# **SIFT Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "921HnOqz_XF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sift_classification_single_img(warped_image, model, matrix_db, names_db, topn=6, nfeatures=500):\n",
        "\n",
        "  prediction = 0\n",
        "  valid_match = 0\n",
        "  sift =  cv2.xfeatures2d.SIFT_create(nfeatures) \n",
        "\n",
        "  # FLANN matcher\n",
        "  FLANN_INDEX_KDTREE = 0\n",
        "  index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "  search_params = dict(checks=50)  \n",
        "  flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
        "\n",
        "  matches_flann = []   \n",
        "  \n",
        "  kp_test, des_test = sift.detectAndCompute(cv2.cvtColor(warped_image,cv2.COLOR_RGB2GRAY), None)\n",
        "  for vector in range(len(matrix_db)):\n",
        "    if type(matrix_db[vector]) is np.ndarray and type(des_test) is np.ndarray:\n",
        "      matches_count = 0 \n",
        "      if len(kp_test) >= 2:\n",
        "          matches = flann.knnMatch(matrix_db[vector], des_test,k=2)\n",
        "          if len(matches[vector]) == 2:\n",
        "            for x,(m,n) in enumerate(matches):\n",
        "              if m.distance < 0.7*n.distance:\n",
        "                  matches_count += 1\n",
        "            matches_flann.append((matches_count,names_db[vector]))\n",
        "  if len(matches_flann) > 2:    \n",
        "    matches_flann.sort(key=lambda x : x[0] , reverse = True)\n",
        "    prediction = matches_flann[:topn]\n",
        "    valid_match = 1\n",
        "\n",
        "  return prediction, valid_match"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihU1dwCDd9RB",
        "colab_type": "text"
      },
      "source": [
        "# **Paintings Detection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVpo0ylstrk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_painting(countour_simple_img, source_img, output_mode, model, matrix_db, names_db):\n",
        "\n",
        "  \n",
        "  contours, hierarchy = cv2.findContours(np.uint8(countour_simple_img), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  # Draw contours\n",
        "  drawing = np.zeros((countour_simple_img.shape[0], countour_simple_img.shape[1], 3), dtype=np.uint8)\n",
        "  contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "  centres = []\n",
        "  area = []\n",
        "  for index, el in enumerate(contours):\n",
        "    if index == 0:\n",
        "      biggest_area = cv2.contourArea(el)\n",
        "    if cv2.contourArea(el) > 20000:\n",
        "        cv2.drawContours(drawing, contours, index, 255, thickness=-1) \n",
        "        moments = cv2.moments(contours[index])\n",
        "        centres.append((int(moments['m10']/moments['m00']), int(moments['m01']/moments['m00'])))\n",
        "        area.append(cv2.contourArea(el))\n",
        "        cv2.circle(drawing, centres[-1], 6, (0, 255, 0), -1)\n",
        "       \n",
        "\n",
        "  midpoint = []\n",
        "  for ref_idx in range(len(centres)):\n",
        "    min_dist = countour_simple_img.shape[0] + countour_simple_img.shape[1]\n",
        "    for comp_idx in range(len(centres)):  \n",
        "         measure = dist.euclidean((centres[ref_idx][0] , centres[ref_idx][1]), (centres[comp_idx][0] , centres[comp_idx][1]))\n",
        "         if measure > 0:\n",
        "          if measure < min_dist:\n",
        "            min_dist = measure\n",
        "\n",
        "    min_dist = int(min_dist/2)\n",
        "    midpoint.append(min_dist) \n",
        "  \n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4,4))\n",
        "  drawing_bin = cv2.cvtColor(drawing, cv2.COLOR_RGB2GRAY)\n",
        "  drawing_bin = cv2.erode(drawing_bin, kernel, iterations = 8)\n",
        "  drawing_bin = cv2.dilate(drawing_bin, kernel, iterations = 2)\n",
        "  drawing_bin = cv2.erode(drawing_bin, kernel,iterations = 2)\n",
        "\n",
        "  #DEBUG\n",
        "  #plt.figure(figsize = (20,10))\n",
        "  #plt.imshow(drawing, cmap=plt.cm.gray, interpolation='nearest')\n",
        "\n",
        "  out = np.zeros_like(source_img)\n",
        "  offset_x = 0\n",
        "  offset_y = 0   \n",
        "  past_coord = [(1,1,1,1)]\n",
        "  first_attempt = False \n",
        "  warped_img = []\n",
        "  predictions = []\n",
        "  boxes = []\n",
        "    \n",
        "  for centre_idx in range(len(centres)):\n",
        "    \n",
        "    sec_margin = 0\n",
        "    coeff = int((0.0005/(centre_idx+1))*area[centre_idx])\n",
        "\n",
        "    if area[centre_idx] <= 0.5*biggest_area:\n",
        "      coeff = int((0.0001/(centre_idx+1))*area[centre_idx])\n",
        "\n",
        "    img_off_x2 = np.clip(centres[centre_idx][0] + int(coeff + midpoint[centre_idx]) + sec_margin, 0 , drawing_bin.shape[1])\n",
        "    img_off_x1 = np.clip(centres[centre_idx][0] - int(coeff + midpoint[centre_idx]) - sec_margin, 0 , drawing_bin.shape[1])\n",
        "    img_off_y2 = np.clip(centres[centre_idx][1] + int(coeff + midpoint[centre_idx]) + sec_margin, 0 , drawing_bin.shape[0])\n",
        "    img_off_y1 = np.clip(centres[centre_idx][1] - int(coeff + midpoint[centre_idx]) - sec_margin, 0 , drawing_bin.shape[0])\n",
        "\n",
        "    cropped = drawing_bin[img_off_y1:img_off_y2,img_off_x1:img_off_x2]\n",
        "  \n",
        "\n",
        "    #### DEBUG #####\n",
        "    #plt.figure(figsize = (20,10))\n",
        "    #plt.imshow(cropped, cmap=plt.cm.gray, interpolation='nearest') \n",
        "\n",
        "    offset_x = 0\n",
        "    if img_off_x1 > 0:\n",
        "          offset_x = img_off_x1 \n",
        "\n",
        "    offset_y = 0\n",
        "    if img_off_y1 > 0:\n",
        "          offset_y = img_off_y1     \n",
        "    \n",
        "    countours_2, hierarchy = cv2.findContours(cropped, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    countours_2 = sorted(countours_2, key=cv2.contourArea, reverse=True)\n",
        "   \n",
        "    for idx, el in enumerate(countours_2):   \n",
        "       \n",
        "      if cv2.contourArea(el) > 10000 and idx == 0: \n",
        "\n",
        "        epsilon = 0.0001 * cv2.arcLength(countours_2[0], True)\n",
        "        approx = cv2.approxPolyDP(countours_2[0], epsilon, True)\n",
        "        \n",
        "        \n",
        "        t = 10        \n",
        "        n = approx.shape[0]\n",
        "\n",
        "        for i in range(n): \n",
        "\n",
        "            p0 = approx[(i+n-1) % n][0]    \n",
        "            p1 = approx[i][0]              \n",
        "            p2 = approx[(i + 1) % n][0]     \n",
        "            dx = (p2[0] + offset_x)-(p1[0] + offset_x)  \n",
        "            dy = (p2[1] + offset_y)-(p1[1] + offset_y)  \n",
        "                      \n",
        "            \n",
        "            if abs(dx) < t:\n",
        "                if ((dx < 0) and (p0[0] > p1[0])) or ((dx > 0) and (p0[0] < p1[0])):\n",
        "                    p2[0] = p1[0]\n",
        "                else:\n",
        "                    p1[0] = p2[0]\n",
        "\n",
        "            \n",
        "            if abs(dy) < t:\n",
        "                if ((dy < 0) and (p0[1] > p1[1])) or ((dy > 0) and (p0[1] < p1[1])):\n",
        "                    p2[1] = p1[1]\n",
        "                else:\n",
        "                    p1[1] = p2[1]\n",
        "                    \n",
        "            approx[i][0] = p1\n",
        "            approx[(i + 1) % n][0] = p2\n",
        "            \n",
        "            \n",
        "        #### DEBUG #####\n",
        "        #dummy = np.zeros((cropped.shape[0], cropped.shape[1], 3), dtype=np.uint8)\n",
        "        #cv2.drawContours(dummy,approx,-1,(0,255,0),10)        \n",
        "        #x,y,w,h = cv2.boundingRect(el)\n",
        "        #cv2.rectangle(dummy,(x,y),(x+w,y+h),(0,0,255),2)\n",
        "        #plt.figure(figsize = (20,10))\n",
        "        #plt.imshow(dummy, cmap=plt.cm.gray, interpolation='nearest')\n",
        "\n",
        "        x_crop,y_crop,w_crop,h_crop = cv2.boundingRect(el)\n",
        "        mask = np.zeros((source_img.shape[0], source_img.shape[1]))\n",
        "        painting_corners_raw = retrieve_points_coordinates(cv2.boundingRect(el), offset_x, offset_y)              \n",
        "        painting_corners = painting_corners_raw.reshape(4,1,2)\n",
        "\n",
        "        if len(approx) < 4:\n",
        "          cv2.fillConvexPoly(0, painting_corners, 1)   \n",
        "        else:     \n",
        "          x,y,w,h = cv2.boundingRect(painting_corners)\n",
        "\n",
        " \n",
        "          if detect_outliers(x,y,w,h,source_img.shape[1],source_img.shape[0]) == False:\n",
        "\n",
        "            no_shadowing = False\n",
        "            for shape in range(len(past_coord)):\n",
        "              \n",
        "              if  (((x >= past_coord[shape][0]) and (x <= (past_coord[shape][0] + past_coord[shape][2]))) and ((y >= past_coord[shape][1]) and (y <= (past_coord[shape][1] + past_coord[shape][3]))))==False\\\n",
        "                  and\\\n",
        "                  ((((x + w) >= past_coord[shape][0]) and ((x + w) <= (past_coord[shape][0] + past_coord[shape][2]))) and (((y + h) >= past_coord[shape][1]) and ((y + h) <= (past_coord[shape][1] + past_coord[shape][3]))))==False:                    \n",
        "\n",
        "                    if first_attempt == False:   \n",
        "                      past_coord[shape] = (x,y,w,h)\n",
        "                      first_attempt =True  \n",
        "                    else:                     \n",
        "                      past_coord.append((x,y,w,h)) \n",
        "                    if no_shadowing == False:\n",
        "                       no_shadowing = True\n",
        "              else:\n",
        "                 no_shadowing = False\n",
        "                 break\n",
        " \n",
        "            if no_shadowing == True:                \n",
        "              median = x+(w/2)                      \n",
        "              painting_corners_warp = order_points_by_clusters(approx.reshape(-2,2), median, offset_x, offset_y)  \n",
        "              #painting_corners_warp = order_points(approx.reshape(-2,2), offset_x, offset_y) \n",
        "              valid_match = painting_classification(source_img[y_crop+offset_y:y_crop+h_crop+offset_y,x_crop+offset_x:x_crop+w_crop+offset_x], model)  \n",
        "              if valid_match > 0.65:\n",
        "                prediction, matches = sift_classification_single_img(perspective_transform(source_img, painting_corners_warp), model, matrix_db, names_db)\n",
        "                if matches > 0:\n",
        "                  warped_img.append(perspective_transform(source_img, painting_corners_warp))\n",
        "                  predictions.append((len(warped_img), prediction))\n",
        "\n",
        "                  cv2.fillConvexPoly(mask, painting_corners_warp, 1)              \n",
        "                  #cv2.fillConvexPoly(mask, sum_offset_coordinates(approx.reshape(-2,2), offset_x, offset_y), 1) \n",
        "                  mask = mask.astype(np.bool)\n",
        "                  out[mask] = source_img[mask]    \n",
        "                  #plt.figure(figsize = (20,10))\n",
        "                  #plt.imshow(out[mask], cmap=plt.cm.gray, interpolation='nearest')  \n",
        "\n",
        "                  #cv2.rectangle(source_img,(x,y),(x+w,y+h),(0,255,0),6) \n",
        "                  boxes.append((x,y,x+w,y+h))                    \n",
        "                  #print('BOX: ' + str((x,y,x+w,y+h))) \n",
        "\n",
        "  overlap = cv2.addWeighted(source_img,0.2,out,0.7,0)\n",
        "\n",
        "  if output_mode == 1:\n",
        "    return source_img,warped_img,predictions,boxes\n",
        "  elif output_mode == 2:\n",
        "    return out,warped_img,predictions,boxes\n",
        "  elif output_mode == 3:\n",
        "    return overlap,warped_img,predictions,boxes "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqJZE_xVFy2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def non_maxima_suppression(start_x1, start_y1, end_x1, end_y1, start_x2, start_y2, end_x2, end_y2):\n",
        "\n",
        "  proceed = False\n",
        "\n",
        "  if  (((start_x1 >= start_x2) and (start_x1 <= (end_x2))) and ((start_y1 >= start_y2) and (start_y1 <= (end_y2))))==False\\\n",
        "      and\\\n",
        "      ((((end_x1) >= start_x2) and ((end_x1) <= (end_x2))) and (((end_y1) >= start_y2) and ((end_y1) <= (end_y2))))==False:  \n",
        "\n",
        "      proceed = True\n",
        "\n",
        "  return proceed    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41q4t3mlfzsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discard_cameras(start_y1, frame):\n",
        "\n",
        "  proceed = False\n",
        "  \n",
        "  if start_y1 > (frame.shape[0]/3):\n",
        "     proceed = True\n",
        "\n",
        "  return proceed "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH_UXiB1eGvu",
        "colab_type": "text"
      },
      "source": [
        "# **People Detection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GF1YgsuO1ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def people_detection(source_img, weightsPath, configPath, external_boxes, people_statue_model):\n",
        "\n",
        "  visualize = 0\n",
        "  human_presence = 0\n",
        "  threshold = 0.5\n",
        "  confidence_thr = 0.57\n",
        "\n",
        "  people_boxes = []\n",
        "  statues_boxes = []\n",
        "  \n",
        "  net = cv2.dnn.readNetFromTensorflow(weightsPath, configPath)\n",
        "\n",
        "  clone = source_img.copy()\n",
        "  image = source_img.copy()\n",
        "\n",
        "  (H, W) = image.shape[:2]\n",
        "\n",
        "  blob = cv2.dnn.blobFromImage(image, swapRB=True, crop=False)\n",
        "  net.setInput(blob)\n",
        "  start = time.time()\n",
        "  (boxes, masks) = net.forward([\"detection_out_final\", \"detection_masks\"])\n",
        "  end = time.time()\n",
        "  # loop over the number of detected objects\n",
        "  for i in range(0, boxes.shape[2]):\n",
        " \n",
        "    classID = int(boxes[0, 0, i, 1])    \n",
        "    confidence = boxes[0, 0, i, 2]\n",
        "\n",
        "    #Only People \n",
        "    if classID == 0:\n",
        "      if confidence > confidence_thr:       \n",
        "        box = boxes[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
        "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "        no_outliers = True\n",
        "        \n",
        "        for i in range(len(external_boxes)):\n",
        "          no_outliers = non_maxima_suppression(startX, startY, endX, endY, external_boxes[i][0],external_boxes[i][1],external_boxes[i][2],external_boxes[i][3])          \n",
        "          \n",
        "          if no_outliers == False:\n",
        "            break\n",
        "\n",
        "          no_outliers = discard_cameras(startY, source_img) \n",
        "\n",
        "          if no_outliers == False:\n",
        "            break \n",
        "\n",
        "        if no_outliers == True:\n",
        "\n",
        "          boxW = endX - startX\n",
        "          boxH = endY - startY\n",
        "         \n",
        "          mask = masks[i, classID]\n",
        "          mask = cv2.resize(mask, (boxW, boxH),interpolation=cv2.INTER_NEAREST)\n",
        "          mask = (mask > threshold)\n",
        "\n",
        "          roi = clone[startY:endY, startX:endX]\n",
        "       \n",
        "          if people_classification(roi, people_statue_model) > 0:\n",
        "\n",
        "            roi = roi[mask]\n",
        "\n",
        "            color = np.array([255,0,0])            \n",
        "            blended = ((0.4 * color) + (0.6 * roi)).astype(\"uint8\")\n",
        "\n",
        "            clone[startY:endY, startX:endX][mask] = blended\n",
        "\n",
        "            color = [int(c) for c in color]\n",
        "            cv2.rectangle(clone, (startX, startY), (endX, endY), color, 2)\n",
        "            people_boxes.append((startX,startY,endX,endY))\n",
        "\n",
        "            text = \"{}: {:.4f}\".format(LABELS[classID], confidence)\n",
        "            cv2.putText(clone, text, (startX, startY - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2, cv2.LINE_AA)\n",
        "            human_presence = 1\n",
        "        \n",
        "          else:\n",
        "            roi = roi[mask]            \n",
        "            \n",
        "            color = np.array([0,0,255])  \n",
        "            blended = ((0.4 * color) + (0.6 * roi)).astype(\"uint8\")\n",
        "            \n",
        "            clone[startY:endY, startX:endX][mask] = blended\n",
        "            color = [int(c) for c in color] \n",
        "            cv2.rectangle(clone, (startX, startY), (endX, endY), color, 2)\n",
        "            statues_boxes.append((startX,startY,endX,endY))\n",
        "\n",
        "            text = 'statue'\n",
        "            cv2.putText(clone, text, (startX, startY - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2, cv2.LINE_AA)\n",
        "\n",
        "  return clone, human_presence, people_boxes, statues_boxes "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaWzJwhzQFAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_bounding_boxes(source_img, boxes):\n",
        "  for i in range(len(boxes)):\n",
        "    cv2.rectangle(source_img,(boxes[i][0],boxes[i][1]),(boxes[i][2],boxes[i][3]),(0,255,0),6) \n",
        "  return source_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om7-0A_3Bx1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resizeAndPad(img, size, padColor=0):\n",
        "\n",
        "  h, w = img.shape[:2]\n",
        "  sw, sh = size\n",
        "\n",
        "  \n",
        "  if h > sh or w > sw:\n",
        "      interp = cv2.INTER_AREA\n",
        "\n",
        "  else: \n",
        "      interp = cv2.INTER_CUBIC\n",
        "\n",
        "  \n",
        "  aspect = float(w)/h \n",
        "  saspect = float(sw)/sh\n",
        "\n",
        "  if (saspect >= aspect) or ((saspect == 1) and (aspect <= 1)):  \n",
        "      new_h = sh\n",
        "      new_w = np.round(new_h * aspect).astype(int)\n",
        "      pad_horz = float(sw - new_w) / 2\n",
        "      pad_left, pad_right = np.floor(pad_horz).astype(int), np.ceil(pad_horz).astype(int)\n",
        "      pad_top, pad_bot = 0, 0\n",
        "\n",
        "  elif (saspect < aspect) or ((saspect == 1) and (aspect >= 1)): \n",
        "      new_w = sw\n",
        "      new_h = np.round(float(new_w) / aspect).astype(int)\n",
        "      pad_vert = float(sh - new_h) / 2\n",
        "      pad_top, pad_bot = np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)\n",
        "      pad_left, pad_right = 0, 0\n",
        "\n",
        "  \n",
        "  if len(img.shape) is 3 and not isinstance(padColor, (list, tuple, np.ndarray)): \n",
        "      padColor = [padColor]*3\n",
        "\n",
        "  \n",
        "  scaled_img = cv2.resize(img, (new_w, new_h), interpolation=interp)\n",
        "  scaled_img = cv2.copyMakeBorder(scaled_img, pad_top, pad_bot, pad_left, pad_right, borderType=cv2.BORDER_CONSTANT, value=padColor)\n",
        "\n",
        "  return scaled_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlbvmGXF-RiL",
        "colab_type": "text"
      },
      "source": [
        "# **Image Collage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMwpQVnT-Qxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_text_on_image(background, counter_img, predictions, num_predictions, ident, width_warp, shift_y,text = ''):\n",
        "\n",
        "  for title in range(num_predictions):\n",
        "      text += str(title+1) + ': '\n",
        "      if len(predictions) > 0:\n",
        "        text += DB_title.get(predictions[counter_img][1][title][1])\n",
        "      space = 80\n",
        "      bold = 1\n",
        "      if title == 0:\n",
        "        bold = 2\n",
        "      cv2.putText(background, text, ( ident + width_warp  + 10, shift_y + (title+1)*space), cv2.FONT_HERSHEY_DUPLEX, 1.5, (200,255,155), bold, cv2.LINE_AA)\n",
        "      text = ''\n",
        "\n",
        "\n",
        "def image_collage(source_img, warp_img, predictions, human_presence, num_predictions=6):\n",
        "\n",
        "  if source_img.shape[1] > source_img.shape[0]:\n",
        "      w = int(1920)\n",
        "      h = int(1080)\n",
        "      n_slot_right = 2\n",
        "      \n",
        "      buffer_x = int(w/5)\n",
        "      buffer_y = int(h/3) \n",
        "      vertical_dim = 2*h + buffer_y\n",
        "      horizontal_dim = 2*w  + 2*buffer_x \n",
        "\n",
        "      width_warp = buffer_x \n",
        "      height_warp = int((h/2))\n",
        "      dim_warp = (width_warp, height_warp)\n",
        "      shift_x = 0\n",
        "      shift_y = 0\n",
        "  else:\n",
        "      h = int(1920)\n",
        "      w = int(1080)\n",
        "      n_slot_right = 6\n",
        "     \n",
        "      buffer_x = int(w/2)\n",
        "      buffer_y = int(h/5)\n",
        "      vertical_dim = 2*w + 3*buffer_y\n",
        "      horizontal_dim = 3*h \n",
        "      \n",
        "      width_warp = buffer_x \n",
        "      height_warp = int((h/2))\n",
        "      dim_warp = (width_warp, height_warp)\n",
        "      shift_x = width_warp\n",
        "      shift_y = 0\n",
        "\n",
        "  dim = (w, h) \n",
        "  source_img = cv2.resize(source_img, dim, interpolation = cv2.INTER_AREA)\n",
        "  background = np.zeros((vertical_dim, horizontal_dim,3), np.uint8)\n",
        " \n",
        "  background[:source_img.shape[0],:source_img.shape[1],:3] = source_img\n",
        " \n",
        "  offset_x = width_warp\n",
        "  offset_y = height_warp\n",
        "  counter_img = 0\n",
        "\n",
        "  \n",
        "  for counter_img, img in enumerate(warp_img): \n",
        "\n",
        "    if counter_img < 6:\n",
        "\n",
        "      resized = resizeAndPad(img, dim_warp, 200)\n",
        "\n",
        "      if n_slot_right == 2:\n",
        "\n",
        "        if counter_img < n_slot_right:\n",
        "          background[shift_y:(shift_y + offset_y), (int(horizontal_dim/2)): (int(horizontal_dim/2)) + width_warp,:3] = resized \n",
        "          print_text_on_image(background, counter_img, predictions, num_predictions, int(horizontal_dim/2), width_warp, shift_y) \n",
        "          shift_y += offset_y\n",
        "        else:\n",
        "          if counter_img%2 != 0:\n",
        "            background[buffer_y + int(buffer_y/2) + (int(vertical_dim/2)): buffer_y + int(buffer_y/2) + (int(vertical_dim/2)) + height_warp, shift_x:(shift_x+offset_x),:3] = resized\n",
        "            print_text_on_image(background, counter_img, predictions, num_predictions, shift_x, width_warp,  buffer_y + int(buffer_y/2) + (int(vertical_dim/2)))\n",
        "            shift_x += 6*offset_x\n",
        "          else:\n",
        "            background[(int(vertical_dim/2)): (int(vertical_dim/2)) + height_warp, shift_x:(shift_x+offset_x),:3] = resized\n",
        "            print_text_on_image(background, counter_img, predictions, num_predictions, shift_x, width_warp, (int(vertical_dim/2))) \n",
        "                    \n",
        "      elif n_slot_right == 6:\n",
        "        if counter_img%2 != 0:          \n",
        "          background[shift_y:(shift_y + offset_y), 2*shift_x + int(shift_x/2): 2*shift_x + int(shift_x/2) + width_warp,:3] = resized \n",
        "          print_text_on_image(background, counter_img, predictions, num_predictions, 2*shift_x + int(shift_x/2), width_warp,  height_warp)\n",
        "          shift_x = offset_x + int(1.5*offset_x)\n",
        "          shift_y = 0\n",
        "          if counter_img > 3:\n",
        "            shift_y = 4*buffer_y + int(buffer_y/2)   \n",
        "        else:            \n",
        "          background[shift_y:(shift_y + offset_y), 2*shift_x + int(shift_x/2): 2*shift_x + int(shift_x/2) + width_warp,:3] = resized\n",
        "          print_text_on_image(background, counter_img, predictions, num_predictions, 2*shift_x + int(shift_x/2), width_warp, shift_y)\n",
        "          shift_y += 2*buffer_y + int(buffer_y/2)\n",
        "          if counter_img > 3:\n",
        "             shift_y += 4*buffer_y + int(buffer_y/2)\n",
        "\n",
        "  \n",
        "  if human_presence > 0 and len(predictions) > 0:\n",
        "    room = \"Room : \" + str(DB_room.get(predictions[0][1][0][1]))\n",
        "    cv2.putText(background, room, (10, 100), cv2.FONT_HERSHEY_DUPLEX, 3, (0,150,255), 2, cv2.LINE_AA)\n",
        "\n",
        "  return background"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1oBqg71DG7x",
        "colab_type": "text"
      },
      "source": [
        "# **Image processing pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7-LWJHzXwaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_processing_pipeline(img, weightsPath, configPath, paint_model, people_statue_model, matrix_db, names_db):\n",
        "\n",
        "  source_img = img.copy().astype(np.uint8)\n",
        "\n",
        "  countour_simple_img = transform_image(source_img)\n",
        "  #DEBUG\n",
        "  #plt.figure(figsize = (20,10))\n",
        "  #plt.imshow(countour_simple_img, cmap=plt.cm.gray, interpolation='nearest')\n",
        "\n",
        "  #Paintings Detection\n",
        "  output_mode = 1\n",
        "  detect_img, warp_img, predictions, painting_boxes = detect_painting(countour_simple_img, source_img, output_mode, paint_model, matrix_db, names_db)\n",
        "\n",
        "  #People/Statues Detection\n",
        "  people_img, human_presence, people_boxes, statues_boxes = people_detection(detect_img, weightsPath, configPath, painting_boxes, people_statue_model)\n",
        "\n",
        "  #Print Paintings Bounding Boxes\n",
        "  boxes_img = print_bounding_boxes(people_img, painting_boxes)\n",
        "\n",
        "  #Final visualization\n",
        "  out_img = image_collage(boxes_img, warp_img, predictions, human_presence)\n",
        "\n",
        "  return out_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlGXuCT2phpn",
        "colab_type": "text"
      },
      "source": [
        "# **Release Video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnMSgtTtCQ5R",
        "colab_type": "code",
        "outputId": "7edd86ef-0c7b-482e-9276-8886f3ec20b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "from IPython.display import HTML\n",
        "\n",
        "class ProcessImage:\n",
        "    def __init__(self, arg1, arg2, arg3, arg4, arg5, arg6):\n",
        "        self.arg1 = arg1\n",
        "        self.arg2 = arg2\n",
        "        self.arg3 = arg3\n",
        "        self.arg4 = arg4\n",
        "        self.arg5 = arg5\n",
        "        self.arg6 = arg6\n",
        "    def __call__(self, image):\n",
        "        out = image_processing_pipeline(image, self.arg1, self.arg2, self.arg3, self.arg4, self.arg5, self.arg6)\n",
        "        return out\n",
        "\n",
        "out_video = root_path + 'OutVideos/IMG_4077_Processed.MP4'\n",
        "clips = VideoFileClip(root_path + 'Videos/IMG_4077.MP4')\n",
        "final_clip = clips.fl_image(ProcessImage(weightsPath, configPath, paint_model, people_statue_model, matrix_db, names_db))\n",
        "#final_clip.set_duration(10).write_videofile(out_video, audio=False) #-->> for shorter videos, ex: 10 seconds duration\n",
        "final_clip.write_videofile(out_video, audio=False)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] >>>> Building video /content/drive/My Drive/Unimore/VCS/Project/OutVideos/IMG_4077_Processed.MP4\n",
            "[MoviePy] Writing video /content/drive/My Drive/Unimore/VCS/Project/OutVideos/IMG_4077_Processed.MP4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 645/646 [2:13:53<00:12, 12.46s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: /content/drive/My Drive/Unimore/VCS/Project/OutVideos/IMG_4077_Processed.MP4 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvIWaeSzvTg9",
        "colab_type": "text"
      },
      "source": [
        "# **Looping over video frames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QEQmJdUw4_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cam = cv2.VideoCapture(root_path + \"Videos/IMG_4077.MP4\") \n",
        "  \n",
        "try: \n",
        "      \n",
        "    # creating a folder named data \n",
        "    if not os.path.exists(root_path + 'Videos/Images'): \n",
        "        os.makedirs(root_path + 'Videos/Images') \n",
        "  \n",
        "# if not created then raise error \n",
        "except OSError: \n",
        "    print ('Error: Creating directory of data') \n",
        "  \n",
        "# frame \n",
        "currentframe = 0\n",
        "# Number of frame \n",
        "n_frame = 0\n",
        "  \n",
        "while(True): \n",
        "      \n",
        "    # reading from video \n",
        "    ret,frame = cam.read() \n",
        "  \n",
        "    if ret: \n",
        "\n",
        "        currentframe += 1  \n",
        "\n",
        "        if currentframe%10 == 0: # in case you want to skip some frames acting here, please\n",
        "          \n",
        "          converted = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "          out_img = image_processing_pipeline(converted, weightsPath, configPath, paint_model, people_statue_model, matrix_db, names_db)\n",
        " \n",
        "          name = root_path + 'Videos/Images/frame' + str(currentframe) + '.jpg'\n",
        "          print ('Creating...' + name) \n",
        "\n",
        "          cv2.imwrite(name, cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))\n",
        "         \n",
        "    else: \n",
        "        break\n",
        "  \n",
        "# Release all space and windows once done \n",
        "cam.release() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL2qupWEEEH-",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}